---
layout: post
title: "[DL] CNN 개념정리"
date: 2023-08-04
categories: [DL]
tags: [dl, cnn]
---

# 합성곱 신경망(CNN)

#### 완전연결 계층(Affine 계층)으로 이뤄진 네트워크의 예

<img src="/assets/img/DL/DL_CNN/cnn1.png" alt="" style="width: 700px">



#### CNN으로 이루어진 네트워크의 예

<img src="/assets/img/DL/DL_CNN/cnn2.png" alt="" style="width: 700px">



### 완전연결 계층의 문제점

-> 데이터 형상 무시 (반면, 합성곱 계층은 데이터 형상을 유지)

<br>
<br>

## 합성곱 연산

<img src="/assets/img/DL/DL_CNN/cnn3.png" alt="" style="width: 700px">

<br>
<br>

## 패딩

### *입력 데이터 주변을 0으로 채우는 기법*

<img src="/assets/img/DL/DL_CNN/cnn4.png" alt="" style="width: 700px">

### 왜 패딩을 사용하는가?

*"입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달할 수 있기 때문 "*

<br>
<br>

## 스트라이드

#### 스트라이드 : 필터를 적용하는 위치의 간격

<img src="/assets/img/DL/DL_CNN/cnn5.png" alt="" style="width: 700px">


#### 패딩, 스트라이드, 출력 크기 계산 수식화

<img src="/assets/img/DL/DL_CNN/cnn6.png" alt="" style="width: 700px">

<br>
<br>


## 3차원 데이터의 합성곱 연산

<img src="/assets/img/DL/DL_CNN/cnn7.png" alt="" style="width: 700px">

### 3차원 데이터 합성곱 연산의 계산 순서

<img src="/assets/img/DL/DL_CNN/cnn8.png" alt="" style="width: 700px">

*"참고 | 3차원의 합성곱 연산에서 주의할 점은 입력 데이터의 채널 수와
필터의 채널 수가 같아야 한다는 것"*

## 블록으로 생각하기

<img src="/assets/img/DL/DL_CNN/cnn9.png" alt="" style="width: 700px">

*"위 사진의 출력 데이터는 한 장의 채널이 1개인 특징 맵. 합성곱 연산의
출력으로 다수의 채널을 내보내려면?"*

<img src="/assets/img/DL/DL_CNN/cnn10.png" alt="" style="width: 700px">

*"FN개의 맵을 모으면 형상이(FN, OH, OW)인 블록이 안성되는데,이 완성된
블록을 다음 계층으로 넘기 겠다는 것이 CNN의 처리 흐름"*

<img src="/assets/img/DL/DL_CNN/cnn11.png" alt="" style="width: 700px">

<br>
<br>

## 배치처리

<img src="/assets/img/DL/DL_CNN/cnn12.png" alt="" style="width: 700px">

*"신경망에 4차원 데이터가 하나 흐를 때마다 N개에 대한 합성곱 연산이
이루어짐, 즉 N회 분의 처리를 한번에 수행함"*

<br>
<br>

## 풀링계층

<img src="/assets/img/DL/DL_CNN/cnn13.png" alt="" style="width: 700px">

- **최대 풀링(Max pooling)**: 대상 영역의 최댓값을 구하는 연산(이미지
    인식분야에서 주로 사용됨)

- **평균 풀링(Average pooling)**: 대상 영역의 평균을 구하는 연산
<br>
<br>

### **풀링 계층의 특징**

- **학습해야할 매개변수가 없음:** 대상영역에서 최댓값이나 평균을 취하는 명확한 처리이므로 특별히 학습할 것이 없음

- **채널 수가 변하지 않음:** 채널마다 독립적으로 계산하기 때문

<img src="/assets/img/DL/DL_CNN/cnn14.png" alt="" style="width: 700px">

*입력 변화에 영향을 적게 받음 -> 입력 데이터의 차이를 풀링이 흡수해 사라지게 함*

<br>

<img src="/assets/img/DL/DL_CNN/cnn15.png" alt="" style="width: 700px">

<br>
<br>

## **합성곱/풀링 계층 구현**



``` python
import numpy as np

x = np.random.rand(10, 1, 28, 28) # 무작위로 데이터 선정
x.shape

---
(10, 1, 28, 28)
```




``` python
x[0].shape
x[1].shape

---
(1, 28, 28)
```





``` python
x[0,0]

---

array([[3.04238173e-01, 5.39727275e-01, 6.52911135e-01, 2.09197346e-01,
        4.90755208e-01, 7.23109833e-01, 5.42210992e-01, 2.72556428e-01,
        ...
        2.48881263e-02, 9.31754380e-01, 1.42992989e-01, 8.09624379e-01]])
```

<br>
<br>

## im2col로 데이터 전개하기

### im2col(이미지에서 행렬로)이란?
*"입력 데이터를 필터링(가중치 계산)하기 좋게 전개하는 함수"*

<img src="/assets/img/DL/DL_CNN/cnn16.png" alt="" style="width: 700px">

<img src="/assets/img/DL/DL_CNN/cnn17.png" alt="" style="width: 700px">

<img src="/assets/img/DL/DL_CNN/cnn18.png" alt="" style="width: 700px">

<br>
<br>

## 합성곱 계층 구현


```python
import sys, os
sys.path.append(os.pardir)
from util import im2col

x1 = np.random.rand(1, 3, 7, 7)
col1 = im2col(x1, 5, 5, stride=1, pad=0)
print(col1.shape)

---

(9, 75)

```




```python
x2 = np.random.rand(10, 3, 7, 7)
col2 = im2col(x2, 5, 5, stride=1, pad=0)
print(col2.shape)


---

(90, 75)
```



```python
# im2col을 사용하여 합성곱 계층 구현

class Convolution:
    def __init__(self, W, b, stride=1, pad=0):
        self.W = W
        self.b = b
        self.stride = stride
        self.pad = pad

    def forward(self, x):
        FN, C, FH, FW = self.W.shape
        N, C, H, W = x.shape
        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)
        out_w = int(1 + (W + 2*self.pad -FW) / self.stride)

        col = im2col(x, FH, FW, self.stride, self.pad)
        col_W = self.W.reshape(FN, -1).T
        out = np.dot(col, col_W) + self.b

        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)

        return out
```

*FN = 필터 개수*  
*C: 채널*  
*FH: 필터 높이*  
*FW: 필터 너비*

<br>
<br>

## 풀링 계층 구현하기

### 풀링 계층 구현순서

1.  **입력 데이터 전개**

2.  **행별 최댓값 구함**

3.  **적절한 모양으로 성형** 

### **forward 처리흐름**

<img src="/assets/img/DL/DL_CNN/cnn19.png" alt="" style="width: 700px">

<br>

<img src="/assets/img/DL/DL_CNN/cnn20.png" alt="" style="width: 700px">



```python
class Pooling:
    def __init__(self, pool_h, pool_w, stride=1, pad=0):
        self.pool_h = pool_h
        self.pool_w = pool_w
        self.stride = stride
        self.pad = pad

    def forward(self, x):
        N, C, H, W = x.shape
        out_h = int(1 + (H - self.pool_h) / self.stride)
        out_w = int(1 + (W - self.pool_w) / self.stride)

        #전개 (1)
        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)
        col = col.reshape(-1, self.pool_h*self.pool_w)

        # 최댓값 (2)
        out = np.max(col, axis=1)

        # 성형 (3)
        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)

        return out
```

<br>
<br>


## CNN 구현하기

<img src="/assets/img/DL/DL_CNN/cnn21.png" alt="" style="width: 700px">

### 초기화 때 받는 인수

-   **input_dim** - 입력 데이터(채널 수, 높이, 너비)의 차원

-   **conv_param** - 합성곱 계층의 하이퍼파라미터(딕셔너리)

-   **hidden_size** - 은닉층(완전연결)의 뉴런 수

-   **output_size** - 출력층(완전연결)의 뉴런 수

-   **weight_init_std** - 초기화 때의 가중치 표준편차



```python
from collections import OrderedDict

class SimpleConvNet:
    def __init__(self, input_dim=(1, 28, 28),
                conv_param={'filter_num':30, 'filter_size':5,
                            'pad':0, 'stride':1},
                hidden_size=100, output_size=10, weight_init_std=0.01):
        filter_num = conv_param['filter_num']
        filter_size = conv_param['filter_size']
        filter_pad = conv_param['pad']
        filter_stride = conv_param['stride']
        input_size = input_dim[1]
        conv_output_size = (input_size - filter_size + 2*filter_pad)
        pool_output_size = int(filter_num * (conv_output_size/2) *
                            (conv_output_size/2))
        
        self.params = {}
        self.params['W1'] = weight_init_std * 
                            np.random.randn(filter_num, input_dim[0],
                                            filter_size, filter_size)
        self.params['b1'] = np.zeros(filter_num)
        self.params['W2'] = weight_init_std * 
                            np.random.randn(pool_output_size,
                                            hidden_size)
        self.params['b2'] = np.zeros(hidden_size)
        self.params['W3'] = weight_init_std * 
                            np.random.randn(hidden_size, output_size)
        self.params['b3'] = np.zeros(output_size)

        self.layers = OrderedDict()
        self.layers['Conv1'] = Convolution(self.params['W1'],
                                        self.params['b1'],
                                        conv_param['stride'],
                                        conv_param['pad'])
        self.layers['Relu1'] = Relu()
        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)
        self.layers['Affine1'] = Affine(self.params['W2'],
                                        self.params['b2'])
        self.layers['Relu2'] = Relu()
        self.layer['Affine2'] = Affine(self.params['W3'],
                                    self.params['b3'])
        self.last_layer = SoftmaxWithLoss()
```



```python
# 추론을 수행하는 predict메서드와 손실 함수의 값을 구하는 loss메서드

def predicd(self, x):
    for layer in self.layers.values():
        x = layer.forward(x)
    return x

def loss(self, x, t):
    y = self.predict(x)
    return self.last_layer.forward(y,t)
```



```python
# 오차역전파법으로 기울기 구하는 구현
def gradient(self, x, t):
    # 순전파
    self.loss(x, t)

    # 역전파
    dout = 1
    dout = self.last_layers.backward(dout)

    layers = list(self.layers.values())
    layers.reverse()
    for layer in layers:
        dout = layer.backward(dout)

    # 결과 저장
    grads = {}
    grads['W1'] = self.layers['Conv1'].dW
    grads['b1'] = self.layers['Conv1'].db
    grads['W2'] = self.layers['Affine1'].dW
    grads['b2'] = self.layers['Affine1'].db
    grads['W3'] = self.layers['Affine2'].dW
    grads['b3'] = self.layers['Affine2'].db

    return grads
```



## CNN 시각화하기

### 1번째 층의 가중치 시각화하기

<img src="/assets/img/DL/DL_CNN/cnn22.png" alt="" style="width: 700px">

*"학습 전 필터는 무작위로 초기화되고 있어 흑백의 정도에 규칙성이
없지만, 학습후에는 규칙성이 있는 이미지가 됨"*

> 학습 전 필터를 무작위로 초기화된 가중치는 아직 입력 이미지의 특징을 잘
> 감지하지 못할 수 있는데, 학습을 통해 이러한 가중치들이 점차 최적화되어
> 입력 이미지의 특징을 잘 감지할 수 있게 됩니다.

*"1번째 층의 합성곱 계층에서는 에지나 블롭 등의 저수준 정보가 추출"*

<br>

<img src="/assets/img/DL/DL_CNN/cnn23.png" alt="" style="width: 700px">

*"원시적인 정보가 뒷단 계층에 전달되는 것이 CNN에서 일어나는 일"*
<br>

### **층 깊이에 따른 추출 정보 변화**

<img src="/assets/img/DL/DL_CNN/cnn24.png" alt="" style="width: 700px">

*"계층이 깊어질수록 더 복잡하고 추상화된 정보가 추출됨, 즉, 층이
깊어지면서 뉴런이 반응하는 대상이 단순한 모양에서 '고급'정보로
변해가고, 사물의 '의미'를 이해하도록 변화"*


<br>
<br>

## 대표적인 CNN

-   **LeNet**

-   **AlexNet**



### LeNet

-   **딥러닝의 초기모델**

-   **손글씨 숫자를 인식하는 네트워크**

<img src="/assets/img/DL/DL_CNN/cnn25.png" alt="" style="width: 700px">

<br>

### AlexNet

<img src="/assets/img/DL/DL_CNN/cnn26.png" alt="" style="width: 700px">

-   **활성화 함수로 ReLU를 이용**

-   **LRN이라는 국소적 정규화를 실시하는 계층을 이용**

-   **드롭아웃을 사용**

*"합성곱 계층과 풀링 계층을 반복하고, 마지막으로 완전 연결 계층을 거치면서 결과를 출력"*

*"AlexNet은 더 많은 합성곱 계층과 완전 연결 계층을 포함하며, 더 많은 학습 가능한 파라미터를 가지고 있음"*

*"이러한 크기와 복잡성 측면에서 AlexNet은 더 많은 컴퓨팅 자원이 필요하고, GPU를 이용한 병렬 처리가 필요한 더 복잡한 모델"*

<br>
<br>

## 주요내용

<img src="/assets/img/DL/DL_CNN/cnn27.png" alt="" style="width: 700px">
